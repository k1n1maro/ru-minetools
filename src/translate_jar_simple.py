#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ JAR –º–æ–¥–æ–≤ Minecraft
–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ main.py –¥–ª—è –∫–≤–µ—Å—Ç–æ–≤
–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –±–∞—Ç—á–∏–Ω–≥–æ–º
"""

import os
import json
import zipfile
import tempfile
import shutil
import time
import pickle
import hashlib
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from translatepy import Translator
from functools import lru_cache

translator = Translator()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –ø–µ—Ä–µ–≤–æ–¥–æ–≤
TRANSLATION_CACHE = {}
CACHE_FILE = "translation_cache.pkl"

def load_translation_cache():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    global TRANSLATION_CACHE
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, 'rb') as f:
                loaded_cache = pickle.load(f)
                TRANSLATION_CACHE.update(loaded_cache)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º update –≤–º–µ—Å—Ç–æ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
            print(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à: {len(TRANSLATION_CACHE)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
        TRANSLATION_CACHE = {}

def save_translation_cache():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ —Ñ–∞–π–ª"""
    try:
        with open(CACHE_FILE, 'wb') as f:
            pickle.dump(TRANSLATION_CACHE, f)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∫—ç—à: {len(TRANSLATION_CACHE)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

def get_cache_key(text, lang_to):
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á –¥–ª—è –∫—ç—à–∞"""
    return hashlib.md5(f"{text}:{lang_to}".encode()).hexdigest()

def analyze_jar_files(jar_files, progress_callback=None):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç JAR —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    
    Returns:
        dict: {
            'total_files': int,
            'need_translation': list,  # JAR —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ –ø–µ—Ä–µ–≤–æ–¥–µ
            'already_translated': list,  # JAR —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã
            'no_files': list,  # JAR —Ñ–∞–π–ª—ã –±–µ–∑ lang/patchouli —Ñ–∞–π–ª–æ–≤
            'no_strings': list,  # JAR —Ñ–∞–π–ª—ã –±–µ–∑ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            'stats': {
                'total_lang_files': int,
                'total_patchouli_files': int,
                'total_strings': int
            }
        }
    """
    result = {
        'total_files': len(jar_files),
        'need_translation': [],
        'already_translated': [],
        'no_files': [],
        'no_strings': [],
        'stats': {
            'total_lang_files': 0,
            'total_patchouli_files': 0,
            'total_strings': 0
        }
    }
    
    for i, jar_file in enumerate(jar_files):
        if progress_callback:
            progress = (i / len(jar_files)) * 100
            progress_callback(progress, f"–ê–Ω–∞–ª–∏–∑ {jar_file.name}...")
        
        try:
            jar_info = {
                'file': jar_file,
                'lang_files': 0,
                'patchouli_files': 0,
                'strings_to_translate': 0,
                'already_translated_strings': 0,
                'status': 'unknown',
                'has_lang_files': False,
                'has_patchouli_files': False,
                'has_russian_lang': False,
                'has_russian_patchouli': False
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
            lang_files = find_lang_files(jar_file)
            en_us_lang_files = [f for f in lang_files if 'en_us.json' in f]
            patchouli_files = find_patchouli_files(jar_file)
            
            jar_info['has_lang_files'] = len(en_us_lang_files) > 0
            jar_info['has_patchouli_files'] = len(patchouli_files) > 0
            jar_info['has_russian_lang'] = has_russian_lang(jar_file)
            jar_info['has_russian_patchouli'] = has_russian_patchouli(jar_file)
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ lang, –Ω–∏ patchouli —Ñ–∞–π–ª–æ–≤ - –Ω–µ—á–µ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
            if not jar_info['has_lang_files'] and not jar_info['has_patchouli_files']:
                jar_info['status'] = 'no_files'
                result['no_files'].append(jar_info)
                continue
            
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è)
            def count_translated_strings(obj):
                count = 0
                if isinstance(obj, dict):
                    for value in obj.values():
                        if isinstance(value, str) and any('\u0400' <= char <= '\u04FF' for char in value):
                            count += 1
                        elif isinstance(value, (dict, list)):
                            count += count_translated_strings(value)
                elif isinstance(obj, list):
                    for item in obj:
                        if isinstance(item, str) and any('\u0400' <= char <= '\u04FF' for char in item):
                            count += 1
                        elif isinstance(item, (dict, list)):
                            count += count_translated_strings(item)
                return count
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º Lang —Ñ–∞–π–ª—ã
            if jar_info['has_lang_files']:
                jar_info['lang_files'] = len(en_us_lang_files)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ lang —Ñ–∞–π–ª–æ–≤
                with zipfile.ZipFile(jar_file, 'r') as jar:
                    for lang_file in en_us_lang_files:
                        try:
                            with jar.open(lang_file) as f:
                                content = json.load(f)
                            
                            file_strings = count_strings_in_json(content)
                            jar_info['strings_to_translate'] += file_strings
                            
                            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)
                            jar_info['already_translated_strings'] += count_translated_strings(content)
                                        
                        except Exception:
                            continue
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º Patchouli —Ñ–∞–π–ª—ã
            if jar_info['has_patchouli_files']:
                jar_info['patchouli_files'] = len(patchouli_files)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ patchouli —Ñ–∞–π–ª–æ–≤
                with zipfile.ZipFile(jar_file, 'r') as jar:
                    for patchouli_file in patchouli_files:
                        try:
                            with jar.open(patchouli_file) as f:
                                content = json.load(f)
                            
                            file_strings = count_strings_in_json(content)
                            jar_info['strings_to_translate'] += file_strings
                            
                            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)
                            jar_info['already_translated_strings'] += count_translated_strings(content)
                                        
                        except Exception:
                            continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –ª–æ–≥–∏–∫–∏
            if jar_info['strings_to_translate'] == 0:
                # –ï—Å—Ç—å —Ñ–∞–π–ª—ã, –Ω–æ –Ω–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                jar_info['status'] = 'no_strings'
                result['no_strings'].append(jar_info)
                
            elif jar_info['already_translated_strings'] == jar_info['strings_to_translate'] and jar_info['already_translated_strings'] > 0:
                # –í—Å–µ —Å—Ç—Ä–æ–∫–∏ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã (–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)
                jar_info['status'] = 'already_translated'
                result['already_translated'].append(jar_info)
                
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–æ—Ç–æ–≤—ã—Ö ru_ru —Ñ–∞–π–ª–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ en_us
                if jar_info['already_translated_strings'] == 0:
                    # –ù–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ en_us —Ñ–∞–π–ª–∞—Ö, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤—ã–µ ru_ru —Ñ–∞–π–ª—ã
                    has_complete_translation = True
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å lang —Ñ–∞–π–ª—ã, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ru_ru.json
                    if jar_info['has_lang_files'] and not jar_info['has_russian_lang']:
                        has_complete_translation = False
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å patchouli —Ñ–∞–π–ª—ã, –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å ru_ru –ø–∞–ø–∫–∞
                    if jar_info['has_patchouli_files'] and not jar_info['has_russian_patchouli']:
                        has_complete_translation = False
                    
                    if has_complete_translation and (jar_info['has_russian_lang'] or jar_info['has_russian_patchouli']):
                        # –ï—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ ru_ru —Ñ–∞–π–ª—ã –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        jar_info['status'] = 'already_translated'
                        result['already_translated'].append(jar_info)
                    else:
                        # –ù—É–∂–¥–∞–µ—Ç—Å—è –≤ –ø–µ—Ä–µ–≤–æ–¥–µ
                        jar_info['status'] = 'need_translation'
                        result['need_translation'].append(jar_info)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
                        result['stats']['total_lang_files'] += jar_info['lang_files']
                        result['stats']['total_patchouli_files'] += jar_info['patchouli_files']
                        result['stats']['total_strings'] += jar_info['strings_to_translate']
                else:
                    # –ï—Å—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –ø–µ—Ä–µ–≤–æ–¥–µ
                    jar_info['status'] = 'need_translation'
                    result['need_translation'].append(jar_info)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ —Ç–æ–ª—å–∫–æ –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                    result['stats']['total_lang_files'] += jar_info['lang_files']
                    result['stats']['total_patchouli_files'] += jar_info['patchouli_files']
                    result['stats']['total_strings'] += (jar_info['strings_to_translate'] - jar_info['already_translated_strings'])
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π —Ñ–∞–π–ª
            jar_info = {
                'file': jar_file,
                'status': 'error',
                'error': str(e)
            }
            result['no_files'].append(jar_info)
    
    if progress_callback:
        progress_callback(100, "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
    
    return result

def translate_batch(texts, lang_to, delay=0.0):
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∞–∫–µ—Ç —Å—Ç—Ä–æ–∫ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏"""
    results = []
    uncached_texts = []
    uncached_indices = []
    cache_hits = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
    for i, text in enumerate(texts):
        if not text or not text.strip():
            results.append(text)
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
        if any('\u0400' <= char <= '\u04FF' for char in text):
            results.append(text)
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
        if (':' in text and len(text) < 50 and not ' ' in text) or \
           '{' in text or '}' in text or len(text) < 3 or \
           text.startswith('#') or text.startswith('//') or \
           text.isdigit() or text.replace('.', '').replace(',', '').isdigit() or \
           len(text.split()) == 1 and len(text) < 10:
            results.append(text)
            continue
        
        cache_key = get_cache_key(text, lang_to)
        if cache_key in TRANSLATION_CACHE:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
            results.append(TRANSLATION_CACHE[cache_key])
            cache_hits += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø–∞–¥–∞–Ω–∏–π
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            results.append(None)  # Placeholder
            uncached_texts.append(text)
            uncached_indices.append(i)
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–∞–∫–µ—Ç–æ–º
    if uncached_texts:
        try:
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –∫ API
            if delay > 0:
                time.sleep(delay)
            
            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è API –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            start_time = time.time()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º
            batch_text = " |SEP| ".join(uncached_texts)
            translated_batch = str(translator.translate(batch_text, lang_to))
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ API
            api_response_time = time.time() - start_time
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ
            translated_parts = translated_batch.split(" |SEP| ")
            
            # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø–æ –æ–¥–Ω–æ–π
            if len(translated_parts) != len(uncached_texts):
                translated_parts = []
                for text in uncached_texts:
                    # –£–±–∏—Ä–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
                    try:
                        translated = str(translator.translate(text, lang_to))
                        translated_parts.append(translated)
                    except Exception:
                        translated_parts.append(text)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for i, (original, translated) in enumerate(zip(uncached_texts, translated_parts)):
                cache_key = get_cache_key(original, lang_to)
                cleaned_translation = translated.replace('"', "''")
                TRANSLATION_CACHE[cache_key] = cleaned_translation
                results[uncached_indices[i]] = cleaned_translation
                
        except Exception as e:
            error_msg = str(e).lower()
            api_warning = None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ API
            if "rate limit" in error_msg or "too many requests" in error_msg:
                api_warning = "‚ö†Ô∏è API –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤"
            elif "blocked" in error_msg or "forbidden" in error_msg:
                api_warning = "üö´ API –ë–õ–û–ö–ò–†–û–í–ö–ê: –î–æ—Å—Ç—É–ø –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ —Å–º–µ–Ω–∏—Ç–µ IP"
            elif "timeout" in error_msg or "connection" in error_msg:
                api_warning = "üåê –°–ï–¢–ï–í–ê–Ø –û–®–ò–ë–ö–ê: –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ —Å–µ—Ä–≤–µ—Ä—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤"
            elif "quota" in error_msg or "limit exceeded" in error_msg:
                api_warning = "üìä –õ–ò–ú–ò–¢ –ò–°–ß–ï–†–ü–ê–ù: –ü—Ä–µ–≤—ã—à–µ–Ω–∞ –¥–Ω–µ–≤–Ω–∞—è –∫–≤–æ—Ç–∞ API"
            else:
                api_warning = f"‚ùå –û–®–ò–ë–ö–ê API: {str(e)}"
            
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            if api_warning:
                print(api_warning)
            
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            for i, original in zip(uncached_indices, uncached_texts):
                results[i] = original
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
            return results, {
                'cache_hits': cache_hits,
                'new_translations': 0,
                'total_strings': len([t for t in texts if t and t.strip()]),
                'api_warning': api_warning,
                'api_error': True,
                'api_response_time': 0
            }
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
    return results, {
        'cache_hits': cache_hits,
        'new_translations': len(uncached_texts),
        'total_strings': len([t for t in texts if t and t.strip()]),
        'api_warning': None,
        'api_error': False,
        'api_response_time': api_response_time if uncached_texts else 0
    }

@lru_cache(maxsize=5000)
def translate_to(string, lang_to):
    """–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∫ –≤ main.py (–æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
    if not string or not string.strip():
        return string
    
    try:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        if any(char in string for char in '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'):
            return string
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (ID, –∫–ª—é—á–∏)
        if (':' in string and len(string) < 50 and not ' ' in string):
            return string
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ñ–∏–≥—É—Ä–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏ (–ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã)
        if '{' in string or '}' in string:
            return string
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        if len(string) < 3:
            return string
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = get_cache_key(string, lang_to)
        if cache_key in TRANSLATION_CACHE:
            return TRANSLATION_CACHE[cache_key]
            
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º
        translated = translator.translate(string, lang_to)
        result = str(translated).replace('"', "''")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        TRANSLATION_CACHE[cache_key] = result
        return result
        
    except Exception as e:
        return string

def count_strings_in_json(content):
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ JSON –æ–±—ä–µ–∫—Ç–µ"""
    if not isinstance(content, dict):
        return 0
    
    count = 0
    for key, value in content.items():
        if isinstance(value, str):
            count += 1
        elif isinstance(value, dict):
            count += count_strings_in_json(value)
        elif isinstance(value, list):
            for item in value:
                if isinstance(item, str):
                    count += 1
                elif isinstance(item, dict):
                    count += count_strings_in_json(item)
    
    return count

def translate_json_file(content, lang_to, progress_callback=None, stop_callback=None):
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç JSON —Ñ–∞–π–ª (lang –∏–ª–∏ patchouli) —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ –±–∞—Ç—á–∏–Ω–≥–æ–º"""
    if not isinstance(content, dict):
        return content, 0, {'cache_hits': 0, 'new_translations': 0, 'total_strings': 0}
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
    all_strings = []
    string_paths = []  # –ü—É—Ç–∏ –∫ —Å—Ç—Ä–æ–∫–∞–º –≤ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
    
    def collect_strings(obj, path=""):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key
                if isinstance(value, str):
                    all_strings.append(value)
                    string_paths.append(current_path)
                elif isinstance(value, (dict, list)):
                    collect_strings(value, current_path)
        elif isinstance(obj, list):
            for i, item in enumerate(obj):
                current_path = f"{path}[{i}]"
                if isinstance(item, str):
                    all_strings.append(item)
                    string_paths.append(current_path)
                elif isinstance(item, (dict, list)):
                    collect_strings(item, current_path)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏
    collect_strings(content)
    total_strings = len(all_strings)
    
    if total_strings == 0:
        return content, 0, {'cache_hits': 0, 'new_translations': 0, 'total_strings': 0}
    
    # –ù–ï –≤—ã–≤–æ–¥–∏–º "–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫" - —ç—Ç–æ –±—É–¥–µ—Ç –≤ callback
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 5 —Å—Ç—Ä–æ–∫ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏
    batch_size = 5
    translated_strings = []
    strings_processed = 0
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞ –¥–ª—è –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞
    total_cache_stats = {'cache_hits': 0, 'new_translations': 0, 'total_strings': 0}
    
    for i in range(0, len(all_strings), batch_size):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –ø–∞–∫–µ—Ç–æ–º
        if stop_callback and stop_callback():
            # –ï—Å–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∞—Å—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            break
            
        batch = all_strings[i:i + batch_size]
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –ø–∞–∫–µ—Ç –±–µ–∑ –∑–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
        batch_translated, cache_stats = translate_batch(batch, lang_to, delay=0.0)
        translated_strings.extend(batch_translated)
        
        # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_cache_stats['cache_hits'] += cache_stats['cache_hits']
        total_cache_stats['new_translations'] += cache_stats['new_translations']
        total_cache_stats['total_strings'] += cache_stats['total_strings']
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ —É–±—Ä–∞–Ω–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        # –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ —á–∞—Å—Ç—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if cache_stats.get('api_warning'):
            # –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ callback
            if progress_callback:
                progress_callback(-1, strings_processed, total_strings, cache_stats, api_warning=cache_stats['api_warning'])
        
        strings_processed += len(batch)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç –¥–ª—è –ª—É—á—à–µ–π –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏
        if progress_callback and (i // batch_size % 1 == 0 or strings_processed >= total_strings):
            progress = (strings_processed / total_strings) * 100 if total_strings > 0 else 0
            # –ü–µ—Ä–µ–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞ –≤ callback
            progress_callback(progress, strings_processed, total_strings, cache_stats)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
    def apply_translations(obj, path=""):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã –∫ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
        if isinstance(obj, dict):
            result = {}
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key
                if isinstance(value, str):
                    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
                    try:
                        string_index = string_paths.index(current_path)
                        result[key] = translated_strings[string_index]
                    except ValueError:
                        result[key] = value
                elif isinstance(value, (dict, list)):
                    result[key] = apply_translations(value, current_path)
                else:
                    result[key] = value
            return result
        elif isinstance(obj, list):
            result = []
            for i, item in enumerate(obj):
                current_path = f"{path}[{i}]"
                if isinstance(item, str):
                    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
                    try:
                        string_index = string_paths.index(current_path)
                        result.append(translated_strings[string_index])
                    except ValueError:
                        result.append(item)
                elif isinstance(item, (dict, list)):
                    result.append(apply_translations(item, current_path))
                else:
                    result.append(item)
            return result
        else:
            return obj
    
    translated_content = apply_translations(content)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–µ —Ä–∞–≤–Ω—ã–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—É)
    actually_translated = sum(1 for orig, trans in zip(all_strings, translated_strings) if orig != trans)
    
    return translated_content, actually_translated, total_cache_stats

def find_lang_files(jar_path):
    """–ù–∞—Ö–æ–¥–∏—Ç —è–∑—ã–∫–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ JAR"""
    lang_files = []
    
    with zipfile.ZipFile(jar_path, 'r') as jar:
        for file_info in jar.infolist():
            path = file_info.filename
            
            # –ò—â–µ–º assets/*/lang/*.json
            if '/lang/' in path and path.endswith('.json'):
                lang_files.append(path)
    
    return lang_files

def find_patchouli_files(jar_path):
    """–ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã Patchouli –≤ JAR"""
    patchouli_files = []
    
    with zipfile.ZipFile(jar_path, 'r') as jar:
        for file_info in jar.infolist():
            path = file_info.filename
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: assets/*/patchouli_books/**/en_us/**/*.json
            # –ú–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–∞—è –≥–ª—É–±–∏–Ω–∞ –º–µ–∂–¥—É patchouli_books –∏ en_us
            if (path.startswith('assets/') and 
                '/patchouli_books/' in path and 
                '/en_us/' in path and 
                path.endswith('.json') and
                not file_info.is_dir()):
                patchouli_files.append(path)
    
    return patchouli_files

def debug_jar_structure(jar_path, show_patchouli_only=True):
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JAR —Ñ–∞–π–ª–∞"""
    print(f"üîç –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JAR: {jar_path.name}")
    
    with zipfile.ZipFile(jar_path, 'r') as jar:
        patchouli_paths = []
        lang_paths = []
        
        for file_info in jar.infolist():
            path = file_info.filename
            
            if '/patchouli_books/' in path:
                patchouli_paths.append(path)
            elif '/lang/' in path and path.endswith('.json'):
                lang_paths.append(path)
        
        if show_patchouli_only:
            if patchouli_paths:
                print("üìö Patchouli –ø—É—Ç–∏:")
                for path in sorted(patchouli_paths)[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    print(f"   {path}")
                if len(patchouli_paths) > 10:
                    print(f"   ... –∏ –µ—â–µ {len(patchouli_paths) - 10} —Ñ–∞–π–ª–æ–≤")
            else:
                print("üìö Patchouli —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        if lang_paths:
            print("üìÑ Lang –ø—É—Ç–∏:")
            for path in sorted(lang_paths):
                print(f"   {path}")
        else:
            print("üìÑ Lang —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    print()

def has_russian_lang(jar_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ —É–∂–µ ru_ru.json –≤ lang"""
    with zipfile.ZipFile(jar_path, 'r') as jar:
        for file_info in jar.infolist():
            if '/lang/ru_ru.json' in file_info.filename:
                return True
    return False

def has_russian_patchouli(jar_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ —É–∂–µ ru_ru –ø–∞–ø–∫–∞ –≤ patchouli"""
    with zipfile.ZipFile(jar_path, 'r') as jar:
        for file_info in jar.infolist():
            path = file_info.filename
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ: assets/*/patchouli_books/**/ru_ru/**/*.json
            if (path.startswith('assets/') and 
                '/patchouli_books/' in path and 
                '/ru_ru/' in path and 
                path.endswith('.json')):
                return True
    return False

def translate_jar(jar_path, output_path, lang_to='ru', replace_original=False, progress_callback=None, stop_callback=None):
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç JAR –º–æ–¥ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –±–∞—Ç—á–∏–Ω–≥–æ–º
    
    Args:
        jar_path: –ø—É—Ç—å –∫ JAR —Ñ–∞–π–ª—É
        output_path: –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        lang_to: —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ (ru)
        replace_original: True = –∑–∞–º–µ–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª, False = —Å–æ–∑–¥–∞—Ç—å _ru.jar
        progress_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (progress, current, total)
        stop_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è)
    """
    # –ù–ï –∑–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à –∑–¥–µ—Å—å - –æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω –æ–¥–∏–Ω —Ä–∞–∑ –≤ –Ω–∞—á–∞–ª–µ
    
    jar_path = Path(jar_path)
    output_path = Path(output_path)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if replace_original:
        output_jar = output_path / jar_path.name
    else:
        output_jar = output_path / f"{jar_path.stem}_ru.jar"
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'lang_files': 0,
        'patchouli_files': 0,
        'strings_translated': 0,
        'cache_hits': 0,
        'new_translations': 0
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
    skip_lang = has_russian_lang(jar_path)
    skip_patchouli = has_russian_patchouli(jar_path)
    
    if skip_lang and skip_patchouli:
        return stats
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_dir = Path(temp_dir)
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º JAR
        with zipfile.ZipFile(jar_path, 'r') as jar:
            jar.extractall(temp_dir)
        
        # 1. –ü–ï–†–ï–í–û–î–ò–ú LANG –§–ê–ô–õ–´
        if not skip_lang:
            lang_files = find_lang_files(jar_path)
            en_us_lang_files = [f for f in lang_files if 'en_us.json' in f]
            
            if not en_us_lang_files:
                print("üìÑ Lang: ‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (en_us.json –Ω–µ –Ω–∞–π–¥–µ–Ω)")
            else:
                print(f"üìÑ Lang: –Ω–∞–π–¥–µ–Ω–æ {len(en_us_lang_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                
                for i, lang_file in enumerate(en_us_lang_files):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ñ–∞–π–ª–æ–º
                    if stop_callback and stop_callback():
                        break
                        
                    lang_file_path = temp_dir / lang_file
                    
                    try:
                        with open(lang_file_path, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                        file_strings = count_strings_in_json(content)
                        
                        if file_strings == 0:
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) ‚ö†Ô∏è –ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                            continue
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º)
                        already_translated = 0
                        for key, value in content.items() if isinstance(content, dict) else []:
                            if isinstance(value, str) and any('\u0400' <= char <= '\u04FF' for char in value):
                                already_translated += 1
                        
                        if already_translated == file_strings:
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) ‚úÖ –í—Å–µ —Å—Ç—Ä–æ–∫–∏ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã ({file_strings}/{file_strings})")
                            continue
                        elif already_translated > 0:
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) üîÑ –ß–∞—Å—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω ({already_translated}/{file_strings} —Å—Ç—Ä–æ–∫)")
                        
                        # –í—ã–≤–æ–¥–∏–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
                        print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) 0.0% - 0/{file_strings} —Å—Ç—Ä–æ–∫")
                        
                        # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ñ–∞–π–ª–∞
                        def file_progress_callback(progress, current, total, cache_stats=None, api_warning=None):
                            if progress_callback:
                                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å Lang —á–∞—Å—Ç–∏
                                # –ü—Ä–æ–≥—Ä–µ—Å—Å —Ñ–∞–π–ª–∞: –æ—Ç 0% –¥–æ 100%
                                # –ü—Ä–æ–≥—Ä–µ—Å—Å –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤: (i + progress/100) / len(en_us_lang_files)
                                file_progress_ratio = (i + progress / 100) / len(en_us_lang_files)
                                # Lang –∑–∞–Ω–∏–º–∞–µ—Ç 0-50% –æ—Ç –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                                adjusted_progress = file_progress_ratio * 50
                                progress_callback(adjusted_progress, current, total)
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å API –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –≤—ã–≤–æ–¥–∏–º –µ–≥–æ
                            if api_warning:
                                print(api_warning)
                                return
                            
                            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                            cache_info = ""
                            if cache_stats:
                                parts = []
                                if cache_stats['cache_hits'] > 0:
                                    parts.append(f"–∫—ç—à: {cache_stats['cache_hits']}")
                                if cache_stats['new_translations'] > 0:
                                    parts.append(f"–Ω–æ–≤—ã—Ö: {cache_stats['new_translations']}")
                                if parts:
                                    cache_info = f" ({', '.join(parts)})"
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—É –∂–µ —Å—Ç—Ä–æ–∫—É
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) {progress:.1f}% - {current}/{total} —Å—Ç—Ä–æ–∫{cache_info}")
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                        translated, translated_count, file_cache_stats = translate_json_file(content, lang_to, file_progress_callback, stop_callback)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞
                        if stop_callback and stop_callback():
                            break
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ ru_ru.json
                        ru_file_path = lang_file_path.parent / 'ru_ru.json'
                        with open(ru_file_path, 'w', encoding='utf-8') as f:
                            json.dump(translated, f, ensure_ascii=False, indent=2)
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —Å–º–∞–π–ª–∏–∫–æ–≤
                        if translated_count > 0:
                            cache_info = ""
                            if file_cache_stats['cache_hits'] > 0:
                                cache_info += f" (–∏–∑ –∫—ç—à–∞: {file_cache_stats['cache_hits']})"
                            if file_cache_stats['new_translations'] > 0:
                                cache_info += f" (–Ω–æ–≤—ã—Ö: {file_cache_stats['new_translations']})"
                            
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {translated_count} —Å—Ç—Ä–æ–∫{cache_info}")
                        else:
                            print(f"üìÑ Lang ({i+1}/{len(en_us_lang_files)}) –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                        
                        stats['lang_files'] += 1
                        stats['strings_translated'] += translated_count
                        stats['cache_hits'] += file_cache_stats['cache_hits']
                        stats['new_translations'] += file_cache_stats['new_translations']
                        
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {lang_file}: {e}")
        else:
            print("üìÑ Lang: ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –µ—Å—Ç—å ru_ru.json)")
        
        # –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ Lang —á–∞—Å—Ç–∏ (50% –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞)
        # –í—ã–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å callback –∏ –Ω–µ –ø—Ä–æ–ø—É—â–µ–Ω—ã –æ–±–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤
        if progress_callback and not (skip_lang and skip_patchouli):
            progress_callback(50, 0, 0)  # 50% –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ Patchouli
        
        # 2. –ü–ï–†–ï–í–û–î–ò–ú PATCHOULI
        if not skip_patchouli:
            patchouli_files = find_patchouli_files(jar_path)
            
            if not patchouli_files:
                print("üìö Patchouli: ‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (en_us –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)")
            else:
                print(f"üìö Patchouli: –Ω–∞–π–¥–µ–Ω–æ {len(patchouli_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                
                for i, patchouli_file in enumerate(patchouli_files):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ñ–∞–π–ª–æ–º
                    if stop_callback and stop_callback():
                        break
                        
                    patchouli_file_path = temp_dir / patchouli_file
                    
                    try:
                        with open(patchouli_file_path, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
                        file_strings = count_strings_in_json(content)
                        
                        if file_strings == 0:
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) ‚ö†Ô∏è –ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                            continue
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º)
                        already_translated = 0
                        def count_translated_strings(obj):
                            nonlocal already_translated
                            if isinstance(obj, dict):
                                for value in obj.values():
                                    if isinstance(value, str) and any('\u0400' <= char <= '\u04FF' for char in value):
                                        already_translated += 1
                                    elif isinstance(value, (dict, list)):
                                        count_translated_strings(value)
                            elif isinstance(obj, list):
                                for item in obj:
                                    if isinstance(item, str) and any('\u0400' <= char <= '\u04FF' for char in item):
                                        already_translated += 1
                                    elif isinstance(item, (dict, list)):
                                        count_translated_strings(item)
                        
                        count_translated_strings(content)
                        
                        if already_translated == file_strings:
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) ‚úÖ –í—Å–µ —Å—Ç—Ä–æ–∫–∏ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã ({file_strings}/{file_strings})")
                            continue
                        elif already_translated > 0:
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) üîÑ –ß–∞—Å—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω ({already_translated}/{file_strings} —Å—Ç—Ä–æ–∫)")
                        
                        # –í—ã–≤–æ–¥–∏–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
                        print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) 0.0% - 0/{file_strings} —Å—Ç—Ä–æ–∫")
                        
                        # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Ñ–∞–π–ª–∞
                        def file_progress_callback(progress, current, total, cache_stats=None, api_warning=None):
                            if progress_callback:
                                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å Patchouli —á–∞—Å—Ç–∏
                                # –ü—Ä–æ–≥—Ä–µ—Å—Å —Ñ–∞–π–ª–∞: –æ—Ç 0% –¥–æ 100%
                                # –ü—Ä–æ–≥—Ä–µ—Å—Å –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤: (i + progress/100) / len(patchouli_files)
                                file_progress_ratio = (i + progress / 100) / len(patchouli_files)
                                # Patchouli –∑–∞–Ω–∏–º–∞–µ—Ç 50-100% –æ—Ç –æ–±—â–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                                adjusted_progress = 50 + (file_progress_ratio * 50)
                                progress_callback(adjusted_progress, current, total)
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å API –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –≤—ã–≤–æ–¥–∏–º –µ–≥–æ
                            if api_warning:
                                print(api_warning)
                                return
                            
                            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                            cache_info = ""
                            if cache_stats:
                                parts = []
                                if cache_stats['cache_hits'] > 0:
                                    parts.append(f"–∫—ç—à: {cache_stats['cache_hits']}")
                                if cache_stats['new_translations'] > 0:
                                    parts.append(f"–Ω–æ–≤—ã—Ö: {cache_stats['new_translations']}")
                                if parts:
                                    cache_info = f" ({', '.join(parts)})"
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—É –∂–µ —Å—Ç—Ä–æ–∫—É
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) {progress:.1f}% - {current}/{total} —Å—Ç—Ä–æ–∫{cache_info}")
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                        translated, translated_count, file_cache_stats = translate_json_file(content, lang_to, file_progress_callback, stop_callback)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∫—É –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞
                        if stop_callback and stop_callback():
                            break
                        
                        # –°–æ–∑–¥–∞–µ–º ru_ru –≤–µ—Ä—Å–∏—é
                        ru_file = patchouli_file.replace('/en_us/', '/ru_ru/')
                        ru_file_path = temp_dir / ru_file
                        ru_file_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        with open(ru_file_path, 'w', encoding='utf-8') as f:
                            json.dump(translated, f, ensure_ascii=False, indent=2)
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —Å–º–∞–π–ª–∏–∫–æ–≤
                        if translated_count > 0:
                            cache_info = ""
                            if file_cache_stats['cache_hits'] > 0:
                                cache_info += f" (–∏–∑ –∫—ç—à–∞: {file_cache_stats['cache_hits']})"
                            if file_cache_stats['new_translations'] > 0:
                                cache_info += f" (–Ω–æ–≤—ã—Ö: {file_cache_stats['new_translations']})"
                            
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {translated_count} —Å—Ç—Ä–æ–∫{cache_info}")
                        else:
                            print(f"üìö Patchouli ({i+1}/{len(patchouli_files)}) –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
                        
                        stats['patchouli_files'] += 1
                        stats['strings_translated'] += translated_count
                        stats['cache_hits'] += file_cache_stats['cache_hits']
                        stats['new_translations'] += file_cache_stats['new_translations']
                        
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {patchouli_file}: {e}")
        else:
            print("üìö Patchouli: ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –µ—Å—Ç—å ru_ru –ø–∞–ø–∫–∞)")
        
        # –£–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ JAR
        with zipfile.ZipFile(output_jar, 'w', zipfile.ZIP_DEFLATED) as jar_out:
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(temp_dir)
                    jar_out.write(file_path, arcname)
    
    return stats

def main():
    import sys
    
    if len(sys.argv) < 3:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python translate_jar_simple.py <input_jar_or_folder> <output_folder> [--replace-original]")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    load_translation_cache()
    
    input_path = Path(sys.argv[1])
    output_path = Path(sys.argv[2])
    replace_original = '--replace-original' in sys.argv
    
    # –ù–∞—Ö–æ–¥–∏–º JAR —Ñ–∞–π–ª—ã
    if input_path.is_file():
        jar_files = [input_path]
    else:
        jar_files = list(input_path.glob('*.jar'))
    
    if not jar_files:
        print("‚ùå JAR —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    print(f"üìö –ù–∞–π–¥–µ–Ω–æ JAR —Ñ–∞–π–ª–æ–≤: {len(jar_files)}")
    print(f"üåê –Ø–∑—ã–∫ –ø–µ—Ä–µ–≤–æ–¥–∞: ru")
    print(f"‚öôÔ∏è –†–µ–∂–∏–º: {'–ó–∞–º–µ–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤' if replace_original else '–°–æ–∑–¥–∞–Ω–∏–µ _ru.jar'}")
    print(f"üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø: –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ + –±–∞—Ç—á–∏–Ω–≥ + –∑–∞–¥–µ—Ä–∂–∫–∏")
    print()
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º
    total_stats = {'lang_files': 0, 'patchouli_files': 0, 'strings_translated': 0}
    successful = 0
    
    for jar_file in jar_files:
        try:
            stats = translate_jar(jar_file, output_path, 'ru', replace_original)
            total_stats['lang_files'] += stats['lang_files']
            total_stats['patchouli_files'] += stats['patchouli_files']
            total_stats['strings_translated'] += stats['strings_translated']
            successful += 1
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {jar_file.name}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à –≤ –∫–æ–Ω—Ü–µ
    save_translation_cache()
    
    print()
    print("üéâ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}/{len(jar_files)}")
    print(f"üìÑ Lang —Ñ–∞–π–ª–æ–≤: {total_stats['lang_files']}")
    print(f"üìö Patchouli —Ñ–∞–π–ª–æ–≤: {total_stats['patchouli_files']}")
    print(f"üìù –°—Ç—Ä–æ–∫ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {total_stats['strings_translated']}")
    print(f"üíæ –ö—ç—à —Å–æ–¥–µ—Ä–∂–∏—Ç: {len(TRANSLATION_CACHE)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")

if __name__ == '__main__':
    main()